{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3: Classification, Evaluation, and Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, you will experience a complete machine learning cycle from data preparation to deployment. You will prepare/preprocess a dataset, make a model, evaluate models to find the best fit and deploy it to a simple web page. Our main objective is to make you try classification and evaluation methods, so we will only apply essential data preprocessing techniques but mainly focus on classification and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the **Adult** dataset from the UCI repository, and more information about the data is available [here](http://archive.ics.uci.edu/ml/datasets/Adult). Since we have removed and changed the dataset for grading purposes, use the one we provide on ilearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on census data, the dataset contains information to check whether income exceeds $50K/yr. The datasets consist of 14 attributes and one binary class variable:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- income: >50K, <=50K\n",
    "\n",
    "- age: continuous.\n",
    "\n",
    "- workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "\n",
    "- fnlwgt: continuous.\n",
    "\n",
    "- education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. education-num: continuous.\n",
    "\n",
    "- education-num: continuous.\n",
    "\n",
    "- marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "\n",
    "- occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "\n",
    "- relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "\n",
    "- race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "\n",
    "- sex: Female, Male.\n",
    "\n",
    "- capital-gain: continuous.\n",
    "\n",
    "- capital-loss: continuous.\n",
    "\n",
    "- hours-per-week: continuous.\n",
    "\n",
    "- native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we have a binary class which can be `>50` or `<=50`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "- Unlike the labs, each function you make here will be **graded**, so it is important to *strictly* follow the instruction.\n",
    "- **Import** all necessary libraries yourself whenever needed. Failure to run any code can affect your grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Total points: 6.0 pt**\n",
    "\n",
    "0. Preparation (0.7 pt)\n",
    " - Task 1: Drop missing values (0.2 pt).\n",
    " - Task 2: Assign X and y (0.1 pt).\n",
    " - Task 3: One-hot encoding (0.1 pt).\n",
    " - Task 4: Train test split (0.1 pt).\n",
    " - Task 5: Standardization (0.2 pt).\n",
    "1. Classification (2.9 pt)\n",
    " - Task 6: Random forest (0.5 pt).\n",
    " - Task 7: SVM with diverse kernels (0.4 pt).\n",
    " - Task 8: Decision tree and Random Forest (2.0 pt).\n",
    "2. Evaluation (1.8 pt)\n",
    " - Task 9: Accuracy, Precision, Recall, F1-score (0.3 pt).\n",
    " - Task 10: AUC/AUPRC (0.3 pt).\n",
    " - Task 11: Apply them together with scikit-learn (0.4 pt).\n",
    " - Task 12: Manual implementation of performance metrics (0.8 pt).\n",
    "3. Deployment (0.6 pt)\n",
    " - Task 13: Save models into a file using pickle (0.4 pt).\n",
    " - Task 14: DASH deployment (0.2 pt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Student information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please provide your information for automatic grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUD_SUID = 'dear9120'\n",
    "STUD_NAME = 'Deepti Arya'\n",
    "STUD_EMAIL = 'dear9120@stud.dsv.su.se'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These libraries will be frequently used throughout the homework. Do not change the block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "RANDOM_STATE = 13579 #Do not change it!\n",
    "np.random.seed(RANDOM_STATE) #Do not change it!\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the **Adult** dataset here using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = pd.read_csv(\"datasets/adult.data\", sep=\",\", header=None, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the line below to give the dataframe proper column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race',  'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can find out some basic information by calling *info(), head()*, and *describe()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education-num   32561 non-null  int64 \n",
      " 5   marital-status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital-gain    32561 non-null  int64 \n",
      " 11  capital-loss    32561 non-null  int64 \n",
      " 12  hours-per-week  32561 non-null  int64 \n",
      " 13  native-country  32561 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "adult.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>3.256100e+04</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.581647</td>\n",
       "      <td>1.897784e+05</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>40.437456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.640433</td>\n",
       "      <td>1.055500e+05</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>12.347429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.178270e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.783560e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.370510e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "count  32561.000000  3.256100e+04   32561.000000  32561.000000  32561.000000   \n",
       "mean      38.581647  1.897784e+05      10.080679   1077.648844     87.303830   \n",
       "std       13.640433  1.055500e+05       2.572720   7385.292085    402.960219   \n",
       "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.178270e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.783560e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.370510e+05      12.000000      0.000000      0.000000   \n",
       "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hours-per-week  \n",
       "count    32561.000000  \n",
       "mean        40.437456  \n",
       "std         12.347429  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Drop missing values (0.2 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no null data, as we checked. However, if you read the dataset description, it says there are missing parts represented as \"?\". You can count them using the same technique we used for checking nulls in the previous lab. We have missing values in specific columns only, and it is about 5% of data records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Task 1-1: Count how many missing values (represented as \"?\" in our case) **each column** has and save it into the variable `missing_values` (0.1 pt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing_values = adult.isin(['?']).sum(axis=0)\n",
    "# CHANGE IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                  0\n",
      "workclass         1836\n",
      "fnlwgt               0\n",
      "education            0\n",
      "education-num        0\n",
      "marital-status       0\n",
      "occupation        1843\n",
      "relationship         0\n",
      "race                 0\n",
      "sex                  0\n",
      "capital-gain         0\n",
      "capital-loss         0\n",
      "hours-per-week       0\n",
      "native-country     583\n",
      "income               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to handle missing values, such as imputation or putting median/mean values, but we will practice the most straightforward way: removing the rows with missing values.\n",
    "\n",
    "- Task 1-2: Complete the function below, removing any rows with missing values (0.1 pt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing_values(df, miss):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "      df: the dataframe (adult in our case)\n",
    "      miss: a character to represent missing value (\"?\" in our case)\n",
    "      \n",
    "    Output: the dataframe without the missing values\n",
    "\n",
    "    Step 1: Replace the value 'miss' with np.nan.\n",
    "    Step 2: Drop the rows having nan values and store the result in data_dropped.\n",
    "    Step 3: Return data_dropped\n",
    "    \n",
    "    \"\"\"\n",
    "    df.replace(miss, np.nan, inplace = True)\n",
    "    data_dropped = df.dropna() # CHANGE IT\n",
    "    \n",
    "    return data_dropped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply `drop_missing_values` function to our dataset `adult` and save the result to `adult_dropped.` This part should be done correctly to get the point. You need to put our dataset and the indicator for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_dropped = drop_missing_values(adult, '?') # CHANGE IT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The output of the function should have the same attributes but only a smaller number of rows. Check how many rows are removed. Your dataset should have 30,162 rows!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_dropped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Assign X and y (0.1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's split our dataset into two parts (`X` for attributes and `y` for labels) to use scikit-learn's various methods.\n",
    "- Use `adult_dropped` from Task 1.\n",
    "- `X` should have all the attributes without the labels (the last column).\n",
    "- `y` should be a Pandas Series only with the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = adult_dropped.drop('income', axis=1)\n",
    "\n",
    "y = adult_dropped.iloc[:, -1]\n",
    "# CHANGE IT!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the type and size here. We expect (30162, 14) for attributes (`X`) and (30162, ) for labels (`y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30162, 14), (30162,), pandas.core.frame.DataFrame, pandas.core.series.Series)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X.shape, y.shape, type(X), type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: One-hot encoding (0.1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, scikit-learn does not support categorical attributes very well even for decision tree, and that means we need to convert them into reasonal form of numeric data to fit the algorithms. There is one way called one-hot encoding, which transforms the categorical data into multiple numeric columns for each possible value. There are various ways to apply this, especially using [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) or [Pandas](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) but here we will use the Pandas function to keep the dataframe structure.\n",
    "\n",
    "- Finish one_hot_encoding function which applies one-hot encoding to a given dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(df):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        df: the attributes (X in our case)\n",
    "    Output: one-hot encoded dataframe\n",
    "    \n",
    "    Step 1: Use pd.get_dummies to convert df to a one-hot-encoded form. \n",
    "            Enable an option called 'drop_first' to remove duplication.\n",
    "    Step 2: Return the one-hot-encoded dataframe.\n",
    "    \n",
    "    * Those steps and suggested method are just for your convenience. You can use your own choice of methods.\n",
    "      However, the result should be the same as the one created with the steps above.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_onehot = pd.get_dummies(df, drop_first= True) # CHANGE IT\n",
    "    return df_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create `X_onehot` by calling `one_hot_encoding` function with `X`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_onehot = one_hot_encoding(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check your result by calling any methods you learned. If you successfully followed the instruction, the output (`X_onehot`) should have 96 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Portugal</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   39   77516             13          2174             0              40   \n",
       "1   50   83311             13             0             0              13   \n",
       "2   38  215646              9             0             0              40   \n",
       "3   53  234721              7             0             0              40   \n",
       "4   28  338409             13             0             0              40   \n",
       "\n",
       "   workclass_Local-gov  workclass_Private  workclass_Self-emp-inc  \\\n",
       "0                False              False                   False   \n",
       "1                False              False                   False   \n",
       "2                False               True                   False   \n",
       "3                False               True                   False   \n",
       "4                False               True                   False   \n",
       "\n",
       "   workclass_Self-emp-not-inc  ...  native-country_Portugal  \\\n",
       "0                       False  ...                    False   \n",
       "1                        True  ...                    False   \n",
       "2                       False  ...                    False   \n",
       "3                       False  ...                    False   \n",
       "4                       False  ...                    False   \n",
       "\n",
       "   native-country_Puerto-Rico  native-country_Scotland  native-country_South  \\\n",
       "0                       False                    False                 False   \n",
       "1                       False                    False                 False   \n",
       "2                       False                    False                 False   \n",
       "3                       False                    False                 False   \n",
       "4                       False                    False                 False   \n",
       "\n",
       "   native-country_Taiwan  native-country_Thailand  \\\n",
       "0                  False                    False   \n",
       "1                  False                    False   \n",
       "2                  False                    False   \n",
       "3                  False                    False   \n",
       "4                  False                    False   \n",
       "\n",
       "   native-country_Trinadad&Tobago  native-country_United-States  \\\n",
       "0                           False                          True   \n",
       "1                           False                          True   \n",
       "2                           False                          True   \n",
       "3                           False                          True   \n",
       "4                           False                         False   \n",
       "\n",
       "   native-country_Vietnam  native-country_Yugoslavia  \n",
       "0                   False                      False  \n",
       "1                   False                      False  \n",
       "2                   False                      False  \n",
       "3                   False                      False  \n",
       "4                   False                      False  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4: Train test split (0.1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to split our dataset further into four parts for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use scikit-learn's `train_test_split` function to divide the dataset into four parts.\n",
    "- Follow the instruction below carefully to get a point!.\n",
    "    - Use `X_onehot` and `y`.\n",
    "    - Assign 20% to a test set.\n",
    "    - Use our random state (`RANDOM_STATE`)\n",
    "    - Enable stratify option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the assigned values and write the train_test_split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_onehot, y, test_size = 0.2, random_state=RANDOM_STATE, stratify = y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the type and size here. We expect 24,129 data instances in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24129, 96), (6033, 96), (24129,), (6033,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5: Standardization (0.2 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the missing value and splitting X and y, we need to take care of our numeric attributes. As you can check from `describe()` function, we have numeric attributes with different mean and standard deviation values. Not all machine learning models require standardization of numeric attributes, but some do. In this homework, SVM might be the case that the standardization is required. It might be better to make a standardized version when performing data preparation. \n",
    "\n",
    "- One-hot encoded data does not need to be standardized! So you need to choose the numeric columns only\n",
    "- You need to import sklearn's `StandardScaler` for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X_train, X_test, numeric):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - X_train: A split training set from Task 4\n",
    "        - X_test: A split test set from Task 5\n",
    "        - numeric: Numeric columns that should be standardized\n",
    "    Output:\n",
    "        - X_train_st: A standardized numeric attributes (ndarray)\n",
    "        - X_test_st: A standardized numeric attributes (ndarray)\n",
    "\n",
    "    Step 1: Initialize StandardScaler into the variable 'sc'.\n",
    "    Step 2: Create X_train_numeric, X_test_numeric by selecting numeric columns from original X_train and X_test.\n",
    "            Use the input 'numeric' to choose the columns.\n",
    "    Step 3: Fit StandardScaler on X_train_numeric. You should only use the numeric columns only.\n",
    "    Step 4: Use trained StandardScaler and run the transform function both on X_train_numeric (for the training set) \n",
    "            and X_test_numeric (for the test set). This job will standardize both training and test sets based on\n",
    "            the statistics of training set. You should only use numeric attributes. Save the outputs to X_train_st and X_test_st.\n",
    "    Step 5: Return X_train_st, X_test_st.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1\n",
    "    sc = StandardScaler() # CHANGE IT\n",
    "    \n",
    "    # Step 2\n",
    "    X_train_numeric = X_train[numeric] # CHANGE IT\n",
    "    X_test_numeric = X_test[numeric] # CHANGE IT\n",
    "    \n",
    "    # Step 3\n",
    "    sc.fit(X_train_numeric)\n",
    "    \n",
    "    # Step 4\n",
    "    # Assign two outputs of transformation function to X_train_st (for the training set) and X_test_st (for the test set)\n",
    "    X_train_st = sc.transform(X_train_numeric) # CHANGE IT\n",
    "    X_test_st = sc.transform(X_test_numeric) # CHANGE IT\n",
    "    \n",
    "    # Step 5\n",
    "    # Note that those two variable should only contain numeric attributes, not the whole ones.\n",
    "    return X_train_st, X_test_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(X_train, X_test, X_train_numeric, X_test_numeric, numeric):\n",
    "    # DO NOT CHANGE THIS FUNCTION\n",
    "    # This function is to ensure that the datasets keep the Pandas DataFrame format.\n",
    "    if X_train.shape == (0, 0): return pd.DataFrame([0]), pd.DataFrame([0])\n",
    "    \n",
    "    X_train_st_df = X_train.copy()\n",
    "    X_train_st_df[numeric] = X_train_numeric\n",
    "    X_test_st_df = X_test.copy()\n",
    "    X_test_st_df[numeric] = X_test_numeric\n",
    "    \n",
    "    return X_train_st_df, X_test_st_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find numeric columns first and assign the column names into the variable `numeric`. You can use `.info()` or `.describe()` function to find numeric columns.\n",
    "- This `numeric` should contain the list of column names as strings, e.g., `['a', 'b', 'c']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.info()\n",
    "numeric = [column for column in X_train.columns if X_train[column].dtype in ['int64', 'float64']] # CHANGE IT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Call `standardize` function to standardize numeric attributes. In this case, the output should only contain numeric attributes. We will merge the categorical features later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numeric, X_test_numeric = standardize(X_train, X_test, numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the mean and standard deviation values of the standardized dataset by running the blocks below. The dataset now should have near zero mean and one standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.82575530e-16, -3.29813861e-17,  8.42203251e-17, -2.82697595e-17,\n",
       "       -4.47604525e-17,  1.41348797e-17])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_numeric.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_numeric.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unfortunately, scikit-learn's StandardScaler does not return DataFrame. Run the block below to recover DataFrame and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_st, X_test_st = merge(X_train, X_test, X_train_numeric, X_test_numeric, numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The final outcome (`X_train_st`) should have 96 columns again, where the numeric attributes have zero mean and one standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Portugal</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15349</th>\n",
       "      <td>0.573186</td>\n",
       "      <td>1.445189</td>\n",
       "      <td>1.128197</td>\n",
       "      <td>0.920024</td>\n",
       "      <td>-0.215303</td>\n",
       "      <td>0.339296</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32181</th>\n",
       "      <td>0.344457</td>\n",
       "      <td>-0.247263</td>\n",
       "      <td>1.128197</td>\n",
       "      <td>-0.147147</td>\n",
       "      <td>-0.215303</td>\n",
       "      <td>1.174001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27666</th>\n",
       "      <td>0.420700</td>\n",
       "      <td>-0.259847</td>\n",
       "      <td>1.128197</td>\n",
       "      <td>-0.147147</td>\n",
       "      <td>-0.215303</td>\n",
       "      <td>0.339296</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19530</th>\n",
       "      <td>-0.646702</td>\n",
       "      <td>-0.079686</td>\n",
       "      <td>1.128197</td>\n",
       "      <td>-0.147147</td>\n",
       "      <td>-0.215303</td>\n",
       "      <td>-0.078057</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>-0.265487</td>\n",
       "      <td>-1.263542</td>\n",
       "      <td>0.344473</td>\n",
       "      <td>-0.147147</td>\n",
       "      <td>-0.215303</td>\n",
       "      <td>-0.078057</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20422</th>\n",
       "      <td>0.725671</td>\n",
       "      <td>1.011503</td>\n",
       "      <td>-0.047389</td>\n",
       "      <td>-0.147147</td>\n",
       "      <td>-0.215303</td>\n",
       "      <td>0.756648</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4661</th>\n",
       "      <td>0.496943</td>\n",
       "      <td>-0.259098</td>\n",
       "      <td>1.128197</td>\n",
       "      <td>-0.147147</td>\n",
       "      <td>-0.215303</td>\n",
       "      <td>0.923589</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898</th>\n",
       "      <td>-0.113001</td>\n",
       "      <td>1.637850</td>\n",
       "      <td>1.911920</td>\n",
       "      <td>13.733710</td>\n",
       "      <td>-0.215303</td>\n",
       "      <td>0.756648</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16619</th>\n",
       "      <td>-0.189244</td>\n",
       "      <td>-0.134077</td>\n",
       "      <td>1.520058</td>\n",
       "      <td>1.733728</td>\n",
       "      <td>-0.215303</td>\n",
       "      <td>0.756648</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18125</th>\n",
       "      <td>-0.417973</td>\n",
       "      <td>-1.336146</td>\n",
       "      <td>0.344473</td>\n",
       "      <td>-0.147147</td>\n",
       "      <td>-0.215303</td>\n",
       "      <td>2.008706</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24129 rows Ã— 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "15349  0.573186  1.445189       1.128197      0.920024     -0.215303   \n",
       "32181  0.344457 -0.247263       1.128197     -0.147147     -0.215303   \n",
       "27666  0.420700 -0.259847       1.128197     -0.147147     -0.215303   \n",
       "19530 -0.646702 -0.079686       1.128197     -0.147147     -0.215303   \n",
       "57    -0.265487 -1.263542       0.344473     -0.147147     -0.215303   \n",
       "...         ...       ...            ...           ...           ...   \n",
       "20422  0.725671  1.011503      -0.047389     -0.147147     -0.215303   \n",
       "4661   0.496943 -0.259098       1.128197     -0.147147     -0.215303   \n",
       "4898  -0.113001  1.637850       1.911920     13.733710     -0.215303   \n",
       "16619 -0.189244 -0.134077       1.520058      1.733728     -0.215303   \n",
       "18125 -0.417973 -1.336146       0.344473     -0.147147     -0.215303   \n",
       "\n",
       "       hours-per-week  workclass_Local-gov  workclass_Private  \\\n",
       "15349        0.339296                False              False   \n",
       "32181        1.174001                 True              False   \n",
       "27666        0.339296                False               True   \n",
       "19530       -0.078057                 True              False   \n",
       "57          -0.078057                False               True   \n",
       "...               ...                  ...                ...   \n",
       "20422        0.756648                False              False   \n",
       "4661         0.923589                False               True   \n",
       "4898         0.756648                False              False   \n",
       "16619        0.756648                False               True   \n",
       "18125        2.008706                False              False   \n",
       "\n",
       "       workclass_Self-emp-inc  workclass_Self-emp-not-inc  ...  \\\n",
       "15349                   False                       False  ...   \n",
       "32181                   False                       False  ...   \n",
       "27666                   False                       False  ...   \n",
       "19530                   False                       False  ...   \n",
       "57                      False                       False  ...   \n",
       "...                       ...                         ...  ...   \n",
       "20422                   False                        True  ...   \n",
       "4661                    False                       False  ...   \n",
       "4898                    False                        True  ...   \n",
       "16619                   False                       False  ...   \n",
       "18125                   False                        True  ...   \n",
       "\n",
       "       native-country_Portugal  native-country_Puerto-Rico  \\\n",
       "15349                    False                       False   \n",
       "32181                    False                       False   \n",
       "27666                    False                       False   \n",
       "19530                    False                       False   \n",
       "57                       False                        True   \n",
       "...                        ...                         ...   \n",
       "20422                    False                       False   \n",
       "4661                     False                       False   \n",
       "4898                     False                       False   \n",
       "16619                    False                       False   \n",
       "18125                    False                       False   \n",
       "\n",
       "       native-country_Scotland  native-country_South  native-country_Taiwan  \\\n",
       "15349                    False                 False                  False   \n",
       "32181                    False                 False                  False   \n",
       "27666                    False                 False                  False   \n",
       "19530                    False                 False                  False   \n",
       "57                       False                 False                  False   \n",
       "...                        ...                   ...                    ...   \n",
       "20422                    False                 False                  False   \n",
       "4661                     False                 False                  False   \n",
       "4898                     False                 False                  False   \n",
       "16619                    False                 False                  False   \n",
       "18125                    False                 False                  False   \n",
       "\n",
       "       native-country_Thailand  native-country_Trinadad&Tobago  \\\n",
       "15349                    False                           False   \n",
       "32181                    False                           False   \n",
       "27666                    False                           False   \n",
       "19530                    False                           False   \n",
       "57                       False                           False   \n",
       "...                        ...                             ...   \n",
       "20422                    False                           False   \n",
       "4661                     False                           False   \n",
       "4898                     False                           False   \n",
       "16619                    False                           False   \n",
       "18125                    False                           False   \n",
       "\n",
       "       native-country_United-States  native-country_Vietnam  \\\n",
       "15349                          True                   False   \n",
       "32181                          True                   False   \n",
       "27666                          True                   False   \n",
       "19530                          True                   False   \n",
       "57                            False                   False   \n",
       "...                             ...                     ...   \n",
       "20422                          True                   False   \n",
       "4661                           True                   False   \n",
       "4898                           True                   False   \n",
       "16619                          True                   False   \n",
       "18125                          True                   False   \n",
       "\n",
       "       native-country_Yugoslavia  \n",
       "15349                      False  \n",
       "32181                      False  \n",
       "27666                      False  \n",
       "19530                      False  \n",
       "57                         False  \n",
       "...                          ...  \n",
       "20422                      False  \n",
       "4661                       False  \n",
       "4898                       False  \n",
       "16619                      False  \n",
       "18125                      False  \n",
       "\n",
       "[24129 rows x 96 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_st\n",
    "#X_train_st.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finishing a simple data processing, let's proceed to our main task, classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will run random forest (RF) and support vector machine (SVM) with different kernels using scikit-learn. Then, we will implement score functions for decision trees and main functions for random forests to understand the concepts better. We will continue to use the pre-processed Adult dataset from Tasks 1-5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6: Random forest (graded, 0.5 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you will run the random forest algorithm using scikit-learn and cross-validation. Detailed information about the random forest in scikit-learn can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "\n",
    "Your task is as follows:\n",
    " 1. Create a random forest classifier `rf`.\n",
    "     - Set the random state defined above (`RANDOM_STATE`).\n",
    "     - Set the number of estimator to 100. \n",
    "     - Check the scikit-learn document to find the right parameter. \n",
    " 2. Report an average cross-validation score `rf_cross_val_score` with stratified k-fold with **cv=5**. You should report the average score, not a list of the scores. Use `X_onehot` and `y`, not the training or test set (0.2 pt). \n",
    " - ***Note that you should report an average cross-validation score, which is one numeric value, not a list of scores.***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state = RANDOM_STATE) # CHANGE IT\n",
    "#rf.fit(X_train_st, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_cross_val_score = cross_val_score(rf, X_onehot, y, cv=5).mean() # CHANGE IT\n",
    "#rf_cross_val_score = np.mean(rf_cross_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run this line to check your score. Your score should be above 0.80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85163467089276"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " 3. Run grid search `gs` with a single dictionary `grid_dict` with two keys.\n",
    "    1) max_depth from 3 to 6 (included).\n",
    "    2) min_samples_split = `[3, 5, 7]`.\n",
    "4. Report the best classifier into the variable `rf_best_classifier`. \n",
    "   - Set **cv=5** for grid search cross-validation. Use our training set (`X_train_st` and `y_train`) to perform the grid search. \n",
    "   - This task can take a few minutes depending on computing power (0.3 pt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "grid_dict = {'max_depth' : [3,4,5,6], 'min_samples_split': [3,5,7]} # CHANGE IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=13579),\n",
       "             param_grid={&#x27;max_depth&#x27;: [3, 4, 5, 6],\n",
       "                         &#x27;min_samples_split&#x27;: [3, 5, 7]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=13579),\n",
       "             param_grid={&#x27;max_depth&#x27;: [3, 4, 5, 6],\n",
       "                         &#x27;min_samples_split&#x27;: [3, 5, 7]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=13579)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=13579)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=13579),\n",
       "             param_grid={'max_depth': [3, 4, 5, 6],\n",
       "                         'min_samples_split': [3, 5, 7]})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gs = GridSearchCV(estimator = rf, param_grid = grid_dict, cv = 5) # CHANGE IT\n",
    "gs.fit(X_train_st, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Report your best classifier instance to `rf_best_classifier` (not the best score or average score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_classifier = gs.best_estimator_ # CHANGE IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=6, min_samples_split=5, random_state=13579)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=6, min_samples_split=5, random_state=13579)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=6, min_samples_split=5, random_state=13579)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 7: SVM with diverse kernels (graded, 0.4 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already tried a simple SVC with the RBF kernel before. Here you will run SVM again, but with different kernels and together with cross-validation. Detailed information about SVC in scikit-learn can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC).\n",
    "\n",
    "Your task is as follows:\n",
    "\n",
    "  1. Create a standard SVC classifier `svc` without setting any parameter.\n",
    "  2. Run a grid search with a list of two dictionaries, one with kernel = `['linear', 'poly', 'rbf']` and the other with C = `[1, 10, 100]`. \n",
    "     - This means you have to create a list containing two different dictionaries inside, not one dictionary with two keys. Each dictionary should only have one key.\n",
    "  3. Report the best classifier into the variable `svm_best_classifier.` Set **cv=5** for grid search cross-validation. \n",
    "     - Use `X_train_st` and `y_train`. \n",
    "     - Depending on computing power (0.3 pt), this task can take a few minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC() # CHANGE IT\n",
    "svc.fit(X_train_st, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_dict = [{'kernel' : ['linear', 'poly', 'rbf']},\n",
    "             {'C' : [1,10,100]}] # CHANGE IT\n",
    "gs = GridSearchCV(svc, grid_dict, cv = 5) # CHANGE IT\n",
    "gs.fit(X_train_st, y_train )\n",
    "svm_best_classifier = gs.best_estimator_ # CHANGE IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n"
     ]
    }
   ],
   "source": [
    "print(svm_best_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  3. Take the best model from grid search and report the **test score** to `svm_gs_score` (0.1 pt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_gs_score = svm_best_classifier.score(X_test_st, y_test) # CHANGE IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8486656721365822\n"
     ]
    }
   ],
   "source": [
    "print(svm_gs_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 8: Decision tree (2.0 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 8 involves manual implementation and uses a different dataset. If you would like to complete scikit-learn related tasks using the same dataset first, please move on to Task 9 and on and come back to Task 8 later.**\n",
    "\n",
    "We will now implement a few modules for the decision tree. Follow the instructions carefully so that you can return a correct result. This task is composed of two sections as follows:\n",
    "\n",
    "  - 8-1. Entropy, Gini index, and information gain (0.7 pt)\n",
    "  - 8-2. Tree implementation (1.3 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first section of this task is to create three functions used to evaluate and grow the tree, which are covered in the lecture. Entropy and Gini index are the two main scores used for it. Information gain is the final score to choose a feature for dividing the node. Those scores are essential for a decision tree to work appropriately, and a wrong score can lead to choosing the features that are not proper for creating a high-performing tree.\n",
    "\n",
    "- For simplicity, you will not use the **adult** dataset in this task but a simple **playgolf** dataset with categorical attributes.\n",
    "- Task 8 is continuous, and the result of the function evaluates the grade. Since one function calls other functions in the task, failing to develop one function can affect the whole grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the playgolf dataset to `playgolf` and check its properties. You can find it in the homework file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "playgolf = pd.read_csv('datasets/playgolf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Outlook', 'Temp', 'Humidity', 'Windy', 'Play Golf'], dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playgolf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Windy</th>\n",
       "      <th>Play Golf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>True</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>False</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Outlook  Temp Humidity  Windy Play Golf\n",
       "0     Rainy   Hot     High  False        No\n",
       "1     Rainy   Hot     High   True        No\n",
       "2  Overcast   Hot     High  False       Yes\n",
       "3     Sunny  Mild     High  False       Yes\n",
       "4     Sunny  Cool   Normal  False       Yes"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playgolf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Task 8-1: Create a Gini index function (0.2 pt).\n",
    "  - The Gini Index is calculated by subtracting the sum of the squared probabilities of each class from one.\n",
    "  - You should double-check the lecture slides and the examples below to ensure you made a correct function.\n",
    "  - You can use `collections.Counter()` to count labels of the dataset.\n",
    "  - DO NOT USE SCIKIT-LEARN FOR THIS TASK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "\n",
    "def gini(dataset):\n",
    "    \"\"\"\n",
    "    A function that calculates the Gini index of a given list.\n",
    "    \n",
    "    Input\n",
    "     - dataset: a list of labels.\n",
    "    Output\n",
    "     - impurity: The Gini index of the list.\n",
    "    \n",
    "    You do not need to keep the output name of this function. The grade only depends on the correct outputs.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    count = collections.Counter(dataset)\n",
    "    \n",
    "    length = len(dataset)\n",
    "    \n",
    "    sqrd_prob_sum = 0\n",
    "    \n",
    "    for label, freq in count.items():\n",
    "        probability = freq/length\n",
    "        sqrd_prob_sum += (probability**2)\n",
    "    \n",
    "\n",
    "    impurity = 1-sqrd_prob_sum # CHANGE IT\n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Your Gini index is expected to have the following results:\n",
    "  - `0.5` for `[0,0,1,1]`\n",
    "  - `0.4082` for `[0,0,0,0,0,1,1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini([0,0,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Report the Gini score of the `Windy` attribute of **playgolf** to `gini_score` (0.2 pt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_score = gini(playgolf['Windy']) # CHANGE IT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print your score here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48979591836734704"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Task 8-2: Create an entropy function (0.2 pt).\n",
    "  - You should double check the lecture slides and the examples below to make sure you made a correct function. \n",
    "  - You can use `collections.Counter()` to count labels of the dataset.\n",
    "  - DO NOT USE SCIKIT-LEARN FOR THIS TASK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def entropy(dataset):\n",
    "    \"\"\"\n",
    "    A function that calculates the entropy of a given list.\n",
    "    \n",
    "    Input\n",
    "     - dataset: a list of labels.\n",
    "    Output\n",
    "     - impurity: entropy value of the list.\n",
    "    \n",
    "    You do not need to keep the output name of this function. The grade only depends on the correct outputs.\n",
    "    \n",
    "    \"\"\"\n",
    "    count = collections.Counter(dataset)\n",
    "    \n",
    "    length = len(dataset)\n",
    "    \n",
    "    entro = 0\n",
    "    \n",
    "    for value, freq in count.items():\n",
    "        probability = freq/length\n",
    "        val = - probability * math.log2(probability)\n",
    "        \n",
    "        entro += val\n",
    "         \n",
    "    impurity = entro # CHANGE IT\n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Your entropy is expected to have the following results:\n",
    "  - `1.0` for `[0,0,1,1]`\n",
    "  - `0.8631` for `[0,0,0,0,0,1,1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy([0,0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.863120568566631"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy([0,0,0,0,0,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Report the entropy score of the `Temp` attribute of **playgolf** to `entropy_score` (0.2 pt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_score = entropy(playgolf['Temp']) # CHANGE IT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print your score here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5566567074628228"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Task 8-3: Create an information gain function (0.3 pt). \n",
    "  - **DO NOT use entropy but only use the Gini index for scores.**\n",
    "  - Check the lecture slides and the examples below to ensure you made a correct function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(labels_start, labels_split):\n",
    "    \"\"\"\n",
    "    Calculate information gain when we have information on label distribution before and after the split operation.\n",
    "    This information gain function receives two values:\n",
    "    \n",
    "    Input:\n",
    "      - labels_start: A single list of all current labels\n",
    "        e.g.) [0,0,0,0,1,1,1,1]\n",
    "      - labels_split: A list of lists representing the split \n",
    "        e.g.) [ [0,0,1,1], [1,1,0,0] ]\n",
    "    \n",
    "    Then, we can calculate information gain by calculating the Gini index before splitting,\n",
    "    and subtract (Gini index of the subset * proportion of the subset) for each list after splitting from there.\n",
    "    \n",
    "    Output:\n",
    "      - info_gain: Information gain\n",
    "    \n",
    "    You do not need to keep the output name of this function. The grade only depends on the correct outputs.\n",
    "    \n",
    "    \"\"\"\n",
    "    gini_start = gini(labels_start)\n",
    "    info_gain = gini_start\n",
    "    \n",
    "    for subsets in labels_split:\n",
    "      prop = len(subsets) /len(labels_start)\n",
    "      gini_subsets = gini(subsets)\n",
    "      info_gain -= prop * gini_subsets\n",
    "\n",
    "    \n",
    "    return info_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_gain([0,0,0,0,1,1,1,1], [[0,0,1,0],[1,1,0,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Your information gain is expected to have the following results:\n",
    "  - `0.0` for `[0,0,0,0,1,1,1,1], [[0,0,1,1],[0,0,1,1]]`\n",
    "  - `0.5` for `[0,0,0,0,1,1,1,1], [[0,0,0,0],[1,1,1,1]]`\n",
    "  - `0.125` for `[0,0,0,0,1,1,1,1], [[0,0,1,0],[1,0,1,1]]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we have labels before and after splitting information. Use those two values to calculate information gain and report it to `info_gain_score` using your own `information_gain` function (0.3 pt). Make sure that your infomation gain function support categorical labels not only binary values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_start = [1,2,1,2,2,1,2,1,3,3,3]\n",
    "labels_split = [[3,3,3],[1,2,1,1],[2,2,1,2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_gain_score = information_gain(labels_start, labels_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print your score here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38842975206611574"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_gain_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have some score functions required to construct the tree. Then, it is time to create the tree itself! \n",
    "\n",
    "- Note that this assignment does not aim to make whole working decision trees and random forests but the core functions to understand the algorithm.\n",
    "\n",
    " The tree works as follows:\n",
    "\n",
    "- Starting from the root, you choose a few attributes to test. This does not need to be all the attributes the dataset has.\n",
    "- Iterate chosen attributes and calculate information gain, assuming you split the dataset based on each attribute.\n",
    "- Choose the column (attribute) with maximum information gain and split the dataset again.\n",
    "- Continue growing the tree by choosing the column in the same way until we meet a closing criterion.\n",
    "\n",
    "Here, we will give you a basic `split` function used to split the dataset based on the attribute. This split function receives the attributes (`X`), the label (`y`), and one `feature` (attribute) of it, and splits the whole dataset based on the categories of the selected feature and returns split data subsets and label subsets. You will use those split values to make a few functions needed for decision trees and random forests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split(X, y, attr):\n",
    "    data_subsets = []\n",
    "    label_subsets = []\n",
    "    \n",
    "    for val in X[attr].unique():\n",
    "        data_subset = []\n",
    "        label_subset = []\n",
    "        for idx, row in X.iterrows():\n",
    "            \n",
    "            if row[attr] == val:\n",
    "                data_subset.append(row)\n",
    "                label_subset.append(y[idx])\n",
    "        \n",
    "        data_subsets.append(pd.DataFrame(data_subset))\n",
    "        label_subsets.append(label_subset)\n",
    "        \n",
    "    return data_subsets, label_subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the result by running the function below, and also check the `Windy` column to understand what the function does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([     Outlook  Temp Humidity  Windy\n",
       "  0      Rainy   Hot     High  False\n",
       "  2   Overcast   Hot     High  False\n",
       "  3      Sunny  Mild     High  False\n",
       "  4      Sunny  Cool   Normal  False\n",
       "  7      Rainy  Mild     High  False\n",
       "  8      Rainy  Cool   Normal  False\n",
       "  9      Sunny  Mild   Normal  False\n",
       "  12  Overcast   Hot   Normal  False,\n",
       "       Outlook  Temp Humidity  Windy\n",
       "  1      Rainy   Hot     High   True\n",
       "  5      Sunny  Cool   Normal   True\n",
       "  6   Overcast  Cool   Normal   True\n",
       "  10     Rainy  Mild   Normal   True\n",
       "  11  Overcast  Mild     High   True\n",
       "  13     Sunny  Mild     High   True],\n",
       " [['No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes'],\n",
       "  ['No', 'No', 'Yes', 'Yes', 'Yes', 'No']])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split(playgolf.drop('Play Golf', axis=1), playgolf['Play Golf'], 'Windy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1      True\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "5      True\n",
       "6      True\n",
       "7     False\n",
       "8     False\n",
       "9     False\n",
       "10     True\n",
       "11     True\n",
       "12    False\n",
       "13     True\n",
       "Name: Windy, dtype: bool"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playgolf['Windy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Task 8-4: The first thing we need to make is the function to choose the attributes. So we receive a dataframe and a strategy and return a list of chosen columns. We can have three different options for selecting attributes (0.3 pt).\n",
    "  - `sqrt`: use the sqrt of total column size to choose the columns\n",
    "  - integer numbers: use the received number for  \n",
    "  - `max`: choose the same number of columns as its original size - return the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_attributes(X, strategy):\n",
    "    \"\"\"\n",
    "    Input\n",
    "        - X: Attributes of the node.\n",
    "        - strategy: a strategy for the number of attributes the algorithm chooses.\n",
    "    Output\n",
    "        - attributes: a list of selected attributes\n",
    "\n",
    "    Step 1: Check the strategy. If the type of strategy is integer, the number of attributes to choose will be that number.\n",
    "            If it's \"sqrt\", then it will be the square root of column size (if it is a floating point number, round it down). \n",
    "            If \"max\", it's the size of the dataset's columns. Put appropriate value to 'num_attr'.\n",
    "    Step 2: Choose 'num_attr' column names from X.columns \"without\" allowing replacement. You can use np.random.choice or equivalent. \n",
    "            Assign the result to 'attributes'.\n",
    "    Step 3: return 'attributes'.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(strategy, int):\n",
    "        \n",
    "      number_attr = strategy # CHANGE IT\n",
    "    \n",
    "    elif strategy == \"Sqrt\" :\n",
    "        number_attr = int(np.sqrt(X.shape[1]))\n",
    "    \n",
    "    elif strategy == \"max\" :\n",
    "       number_attr = X.shape[1] \n",
    "           \n",
    "    else :\n",
    "        raise ValueError(\"Invalid \")\n",
    "    attributes = np.random.choice(X.columns, size = number_attr, replace = False ).tolist() # CHANGE IT\n",
    "        \n",
    "    return attributes # CHANGE IT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can test your method here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Humidity', 'Windy']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_attributes(playgolf.drop('Play Golf', axis=1), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Temp', 'Outlook', 'Windy', 'Humidity']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_attributes(playgolf.drop('Play Golf', axis=1), \"max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Task 8-5: Now we have a method to choose attributes. Then now we need to make a function to iterate those selected attributes in the dataset and eventually can make a function for choosing the best feature to split, given the dataset of the node (It will be a full dataset if we run this function on the root node.). The function receives the datasets (`X`, `y`) and the list of selected attributes calculated by `selected_attributes` function (or it can also be user input), and returns the best feature among the chosen one and it's information gain. This process is one of the core processes of the decision tree (0.3 pt). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_info_gain_per_attribute(X, y, attributes):\n",
    "    \"\"\"\n",
    "    Input\n",
    "        - X: Attributes of the node.\n",
    "        - y: dataset labels.\n",
    "        - attributes: the selected attributes to test.\n",
    "    Output\n",
    "        - best_feature: The best feature in terms of information gain.\n",
    "        - best_gain: The information gain value when the dataset is split by the best feature.\n",
    "        \n",
    "    Step 1: Initialize two variables: Set best_info_gain to zero and best_attr to None.\n",
    "    Step 2: You should iterate the attributes we get as input.\n",
    "            For each chosen attribute, 'split' the dataset using the split function we have offered.\n",
    "            This will return sets of attributes and labels. Save the split attributes and labels.\n",
    "    Step 3: Calculate the information gain of the current split in the iteration. \n",
    "            Use the information_gain function you created and the label information from Step 3.\n",
    "    Step 4: Compare it to the current best gain. If the new gain is higher (not higher or equal to), reset best_gain and best_feature.\n",
    "    Step 5: Return best_attr, best_info_gain.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    # Step 1\n",
    "    best_info_gain = 0 # CHANGE IT\n",
    "    best_attr = None\n",
    "    \n",
    "    # Step 2 - You should create a for loop and Step 4 and 5 will run inside the loop\n",
    "        # Step 3\n",
    "        # Step 4\n",
    "    for attri in attributes:\n",
    "        \n",
    "        attri_split, attri_labels = split(X, y, attri)\n",
    "        info_gain = information_gain(y, attri_labels)\n",
    "        if best_info_gain < info_gain:\n",
    "            best_info_gain = info_gain\n",
    "            best_attr = attri\n",
    "    # Step 5\n",
    "    return best_attr, best_info_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we can check and you need to answer here! - which attribute is better in terms of information gain between `Windy` and `Outlook`?\n",
    "  - Answering this question is also part of Task 8-5.\n",
    "  - You should not put the string value yourself. Save the outcome of `check_info_gain_per_attribute` function that answers the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute = ['Windy', 'Outlook']\n",
    "\n",
    "better_attribute, better_attr_info_gain = check_info_gain_per_attribute(playgolf.drop('Play Golf', axis = 1), playgolf['Play Golf'], playgolf[attribute]) # CHANGE IT\n",
    "#best_attr , best_attr_info_gain = check_info_gain_per_attribute(playgolf.drop('Play Golf', axis = 1), playgolf['Play Golf'], select_attributes(playgolf.drop('Play Golf', axis=1), \"max\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlook\n",
      "0.11632653061224485\n"
     ]
    }
   ],
   "source": [
    "print(better_attribute)\n",
    "print(better_attr_info_gain)\n",
    "#print(best_attr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 8-6: Now we can create a wrapper function that calls two separate function: `select_attributes`, and `check_info_gain_per_attribute`. Now, the function receives data `X`, `y`, and `strategy` and calls `select_attributes` with `strategy` to get a list of attributes. Next it calls `check_info_gain_per_attribute` with selected attributes and finally return the best attribute and the corresponding information gain (0.2 pt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.2 pt\n",
    "def best_split(X, y, strategy):\n",
    "    \"\"\"\n",
    "    Input\n",
    "        - X: Attributes of the node.\n",
    "        - y: dataset labels.\n",
    "        - strategy: a strategy for the number of attributes the algorithm chooses.\n",
    "    Output\n",
    "        - best_feature: The best feature in terms of information gain.\n",
    "        - best_gain: The information gain value when the dataset is split by the best feature.\n",
    "\n",
    "    Complete the function following the instructions above\n",
    "    \"\"\"\n",
    "    selected_attributes = select_attributes(X, strategy)\n",
    "    \n",
    "    best_attr, best_info_gain =  check_info_gain_per_attribute(X,y,selected_attributes)  # CHANGE IT\n",
    "    \n",
    "    return best_attr, best_info_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the best split of the playgolf dataset with `strategy` = `sqrt`. Report the best feature and best gain to `best_attr_playgolf` and `best_gain_playgolf`.\n",
    "   - Answering the question here is part of Task 8-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_STATE)\n",
    "best_attr_playgolf, best_gain_playgolf = best_split(playgolf.drop('Play Golf', axis = 1),  playgolf['Play Golf'], \"Sqrt\") # CHANGE IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Windy', 0.030612244897959162)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST YOUR RESULT HERE\n",
    "best_attr_playgolf, best_gain_playgolf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 8-7: Now we have functions 1) to split the function based on one chosen feature (`split`) and 2) to choose the best feature to split (`best_split`). The next step will be to create one tree with all the information we have. Finish the function `build`. This function makes one tree of the random forest by using two previous functions. Since this function is a recursive one, it will return a complete tree, not a node (0.5 pt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.5 pt\n",
    "\n",
    "def build(X, y, strategy, max_depth = 5, min_samples_leaf = 5, tol=0.00001, _depth = 0):\n",
    "    \"\"\"\n",
    "    Input\n",
    "        - X: Attributes of the data\n",
    "        - y: dataset labels\n",
    "        - strategy: a strategy for the number of attributes the algorithm chooses.\n",
    "        - max_depth: maximum allowed depth of the tree\n",
    "        - min_samples_leaf: minimum number of data instances required to continue\n",
    "        - tol: information gain tolerance value.\n",
    "        - _depth: current depth of tree starting from zero (root). Only controlled by the algorithm.\n",
    "    Output\n",
    "        - node: a leaf or middle node.\n",
    "    \n",
    "    Step 0: Consider some stopping criteria. We do not continue this function if ONE of the following conditions is met:\n",
    "        1. if the current depth number is bigger than max_depth\n",
    "        2. if the current sample size is smaller than min_samples_leaf\n",
    "      Check these conditions and terminate the function if required. When terminating, return {\"type\": \"leaf\", \"majority\": the most common class label (y)}.\n",
    "    Step 1: Run the best split function to get the best attributes and the best information gain for the node.\n",
    "    Step 2: Examine the best information gain value. If it is lower than the tolerance value (tol), \n",
    "            return the node with the best information gain value. The node should be a dictionary form \n",
    "            {\"type\": \"leaf\", \"gain\": the best information gain, \"majority\": the most common class label (y)}.\n",
    "    Step 3: If the best information gain is higher, split the dataset with the chosen best attribute.\n",
    "    Step 4: Create an empty list called \"branches\" to save all the branches of the current node. \n",
    "            This branches list will contain the returned values of the recursive calls of the build function.\n",
    "    Step 5: Run this 'build' function recursively for each split attribute and label and store the result\n",
    "            to the  \"branches\" list **only if the returned value is not False (from termination)**.\n",
    "            Remember to increase the depth value so we can trace the max_depth.\n",
    "            Note that depending on your implementation your indices for X and y may mismatch. You need to always make sure that your featurea and labels are correctly ordered.\n",
    "    Step 6: After all the recursion process is done, return the root node with its best attribute, branch information (i.e., \"branches\" list),\n",
    "            and the best information gain (fill in the right variables into the dictionary!).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 0\n",
    "    if(_depth>max_depth) or (len(X.columns)<min_samples_leaf):\n",
    "        return False\n",
    "    else:\n",
    "        #step1\n",
    "        best_attr, best_info_gain = best_split(X, y, strategy)\n",
    "      \n",
    "\n",
    "    # Step 2 - Change the if condition and the return value\n",
    "    if best_info_gain < tol :\n",
    "        \n",
    "        return {\"type\": \"leaf\", \n",
    "                \"gain\": best_info_gain } # CHANGE IT\n",
    "    \n",
    "    # Step 3\n",
    "    split_attrs, split_labels = split(X, y, best_attr) # CHANGE IT\n",
    "    \n",
    "    # Step 4\n",
    "    branches = []\n",
    "         \n",
    "    # Step 5 - You should create a for loop following the manual\n",
    "    for attri, label in zip(split_attrs,split_labels):\n",
    "        X= pd.DataFrame(attri).reset_index(drop= True)\n",
    "        y= pd.Series(label)\n",
    "\n",
    "        branch = build(X,y, strategy=strategy, max_depth=max_depth, min_samples_leaf=min_samples_leaf, _depth = _depth)\n",
    "        if bool(branch) != False:\n",
    "            branches.append(branch)\n",
    "        _depth += 1\n",
    "    # Step 6 - Change None values to the correct values\n",
    "    return {\n",
    "        \"type\": \"node\",\n",
    "        \"best_feature\": best_attr,\n",
    "        \"branches\": branches,\n",
    "        \"value\": best_info_gain,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bulid one tree using the whole playgolf dataset and report the tree to the variable 'single_tree'. Set the strategy to \"sqrt\", max_depth to 3, and min_samples_leaf to 2. You do not need to specify the tolerance value (0.5 pt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "single_tree = build(playgolf.drop('Play Golf', axis = 1), playgolf['Play Golf'], strategy= 'Sqrt' , max_depth=3 , min_samples_leaf=2) # CHANGE IT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print your result here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'node',\n",
       " 'best_feature': 'Windy',\n",
       " 'branches': [{'type': 'node',\n",
       "   'best_feature': 'Humidity',\n",
       "   'branches': [{'type': 'node',\n",
       "     'best_feature': 'Outlook',\n",
       "     'branches': [{'type': 'leaf', 'gain': 0},\n",
       "      {'type': 'leaf', 'gain': 0},\n",
       "      {'type': 'leaf', 'gain': 0}],\n",
       "     'value': 0.5},\n",
       "    {'type': 'leaf', 'gain': 0}],\n",
       "   'value': 0.125},\n",
       "  {'type': 'node',\n",
       "   'best_feature': 'Temp',\n",
       "   'branches': [{'type': 'leaf', 'gain': 0},\n",
       "    {'type': 'leaf', 'gain': 0},\n",
       "    {'type': 'node',\n",
       "     'best_feature': 'Outlook',\n",
       "     'branches': [{'type': 'leaf', 'gain': 0}],\n",
       "     'value': 0.4444444444444444}],\n",
       "   'value': 0.11111111111111116}],\n",
       " 'value': 0.030612244897959162}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 9: Accuracy, Precision, Recall, F1-score (0.3 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start to use our original dataset again! Remember that we have the standardized datasets (`X_train_st` and `X_test_st`). You will evaluate the random forest and the support vector machine classifier with various performance measures you have learned besides accuracy, such as precision, recall, and F1-score, also using scikit-learn. Here, we continue to use the same dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Throughout the task, use standardized datasets (`X_train_st`, `X_test_st`). To use the various score functions here, you need to convert the labels of `y_train` and `y_test` (`<=50K`, `>50K`) to numeric ones (0 or 1) since the score functions will not recognize the categorical labels. Create `y_train_numeric` and `y_test_numeric` with the converted labels (`<=50K` to 0, and `>50K` to 1). Refer to the previous labs. (0.1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtask 1: 0.1 pt\n",
    "\n",
    "y_train_numeric = y_train.replace({'<=50K':0, '>50K' : 1})\n",
    "y_test_numeric = y_test.replace({'<=50K':0, '>50K' : 1 })\n",
    "#print(y_train_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if you successfully replaced the values here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0], dtype=int64), array([0, 1], dtype=int64))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_numeric.unique() , y_test_numeric.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create an instance of an SVC classifier with the **polynomial** kernel and fit the model using the training set. You can use any variable name for your SVC instance. Report the precision score, recall score, and F1-score on the test set, and save it into the variable `precision_score_svc`, `recall_score_svc`, and `f1_score_svc` (0.2 pt). \n",
    "  - You can find out the information about the performance measures [here](https://scikit-learn.org/stable/modules/model_evaluation.html#precision-recall-f-measure-metrics). We require you to calculate the scores using the following functions in scikit-learn: `precision_score`, `recall_score`, and `f1_score`. \n",
    "  - Use the `macro` average option - you can read more about it [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html).\n",
    "  - There is no partial point if you are correct on only some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtask 2: 0.2 pt\n",
    "svc = SVC(kernel= 'poly')\n",
    "svc.fit(X_train_st, y_train_numeric)\n",
    "y_pred_svc = svc.predict(X_test_st) \n",
    "precision_score_svc = precision_score(y_test_numeric, y_pred_svc, average= 'macro') # CHANGE IT\n",
    "recall_score_svc = recall_score(y_test_numeric, y_pred_svc, average='macro') # CHANGE IT\n",
    "f1_score_svc = f1_score(y_test_numeric, y_pred_svc, average= 'macro') # CHANGE IT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print three scores here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8110794247077231, 0.7462773096476087, 0.7695547365499339)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score_svc, recall_score_svc, f1_score_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 10: AUC / AUPRC (0.3 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will evaluate the random forest and the support vector machine classifier with various performance measures related to the ROC curve, such as the area under the ROC curve (AUC) and the area under the precision-recall curve (AUPRC). Use the same dataset as the ones for Task 7 (`X_train_st` and `y_train_numeric`). AUPRC and AUC scores also only recognize numeric labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create an instance of a random forest classifier without setting any constraint. Don't forget to set the random state to our value `RANDOM_STATE` and fit the model on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "rf_10 = rf_clf.fit(X_train_st, y_train_numeric) # CHANGE IT\n",
    "y_pred_rf = rf_clf.predict(X_test_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the accuracy on the test set to `accuracy_rf` (0.1 pt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8483341621084037\n"
     ]
    }
   ],
   "source": [
    "accuracy_rf = accuracy_score(y_test_numeric, y_pred_rf) # CHANGE IT\n",
    "print(accuracy_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Report AUC and AUPRC using the test set and save it into the variable *auc_rf, auprc_rf*. You can find out the information about the performance measures [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score) for AUC score, and [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html) for AUPRC score (0.2 pt). \n",
    "  - AUPRC has many names and is supported as *average precision score* in scikit-learn. We require you to calculate the scores using the following functions: *roc_auc_score, average_precision_score*. If you are correct on only some of them, there is no partial point.\n",
    "  - You should use the probability of the predictions to calculate AUC/AUPRC.\n",
    "  - Use the `weighted` average option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_auc = rf_10.predict_proba(X_test_st)[:, 1]\n",
    "auc_rf = roc_auc_score(y_test_numeric, y_pred_auc, average= 'weighted')  # CHANGE IT\n",
    "auprc_rf = average_precision_score(y_test_numeric, y_pred_auc, average= 'weighted')# CHANGE IT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print your scores here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8483341621084037, 0.9001796618706874, 0.7680117192095133)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(accuracy_rf, auc_rf, auprc_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 11: Apply them together with scikit-learn (0.4 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you will try to apply the grid search using the performance measures you have tried on Task 5 and Task 6 and pick the best-performing model in terms of specific performance measures.\n",
    "\n",
    "Our dataset is imbalanced, meaning that the healthy patient is dominant. Therefore, we can expect that the best model can be different, and we may also need to use AUPRC to get the most suitable model. \n",
    "\n",
    "Your task is as follows:\n",
    "\n",
    "1. Use the same dataset as the ones for Task 7 (`X_train_st` and `y_train_numeric`). AUPRC and precision scores also only recognize numeric labels.\n",
    "2. Create an instance of a kNN classifier without setting any constraints. \n",
    "3. Run grid search with a dictionary - here, you need to search the number of neighbors for kNN from 1 to 10 (included) and use two different scoring measures: AUPRC and precision. Set `cv=3` for grid search cross-validation. **Do not specify any average option.**\n",
    "4. Put the best classifiers into the respective variable called `auprc_best_classifier` and `precision_best_classifier`. Note that we would like to get **two** best classifiers per evaluation score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you complete the method, you can run the following line to check whether your functions are correct. We will evaluate your functions with different data, so implement them carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "#knn.fit(X_train_st,y_train_numeric)\n",
    "knn_params = {'n_neighbors' : range(1,11)}\n",
    "\n",
    "scorers = {\n",
    "  'AUPRC': make_scorer(average_precision_score),\n",
    "  'Precision' : make_scorer(precision_score)\n",
    "}\n",
    "\n",
    "gs_auprc = GridSearchCV(knn, param_grid=knn_params, scoring= scorers, cv = 3, refit= 'AUPRC')\n",
    "gs_auprc.fit(X_train_st, y_train_numeric)\n",
    "\n",
    "gs_precision = GridSearchCV(knn, param_grid=knn_params, scoring=scorers, cv = 3, refit='Precision')\n",
    "gs_precision.fit(X_train_st, y_train_numeric)\n",
    "auprc_best_classifier = gs_auprc.best_estimator_ # CHANGE IT\n",
    "precision_best_classifier = gs_precision.best_estimator_ # CHANGE IT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your best classifiers here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(KNeighborsClassifier(n_neighbors=9), KNeighborsClassifier(n_neighbors=10))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(auprc_best_classifier, precision_best_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 12: Task 5 implementation (0.8 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task requires you to implement the following performance measures:\n",
    " - Accuracy (0.2 pt)\n",
    " - Precision (0.2 pt)\n",
    " - Recall (0.2 pt)\n",
    " - F1-score (0.2 pt)\n",
    " \n",
    "All inputs will be the NumPy arrays, so you can use any NumPy array methods to calculate the scores.\n",
    "  - **Scikit-learn methods are not allowed**\n",
    "  - Looping the list is not allowed\n",
    "  - Copying materials from the internet is completely prohibited\n",
    "\n",
    "We want you to calculate the **micro** average for Precision and Recall. Read more about it [here](https://tomaxent.com/2018/04/27/Micro-and-Macro-average-of-Precision-Recall-and-F-Score/). You can always validate your method by comparing the result to the one from scikit-learn.\n",
    "\n",
    "We only test these functions with binary values so you do not need to handle categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_manual(truth, predicted):\n",
    "    \n",
    "    TP = np.sum((truth == 1) & (predicted == 1))\n",
    "    TN = np.sum((truth == 0) & (predicted == 0))\n",
    "    \n",
    "    FN = np.sum((truth == 1) & (predicted == 0))\n",
    "    FP = np.sum((truth == 0) & (predicted == 1))\n",
    "    \n",
    "    accuracy = (TP + TN)/(TP+TN+FP+FN)\n",
    "    \n",
    "    return accuracy # CHANGE IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_manual(truth, predicted):\n",
    "    TP = np.sum((truth == 1) & (predicted == 1))\n",
    "    TN = np.sum((truth == 0) & (predicted == 0))\n",
    "    \n",
    "    FN = np.sum((truth == 1) & (predicted == 0))\n",
    "    FP = np.sum((truth == 0) & (predicted == 1))\n",
    "    \n",
    "    precision = TP/(TP+FP)\n",
    "    \n",
    "    return precision # CHANGE IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_manual(truth, predicted):\n",
    "    TP = np.sum((truth == 1) & (predicted == 1))\n",
    "    TN = np.sum((truth == 0) & (predicted == 0))\n",
    "    \n",
    "    FN = np.sum((truth == 1) & (predicted == 0))\n",
    "    FP = np.sum((truth == 0) & (predicted == 1))\n",
    "    \n",
    "    recall = TP / (TP+FN)\n",
    "    \n",
    "    return recall # CHANGE IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_manual(truth, predicted):\n",
    "    TP = np.sum((truth == 1) & (predicted == 1))\n",
    "    TN = np.sum((truth == 0) & (predicted == 0))\n",
    "    \n",
    "    FN = np.sum((truth == 1) & (predicted == 0))\n",
    "    FP = np.sum((truth == 0) & (predicted == 1))\n",
    "    \n",
    "    f1_score = 2 * precision_manual(truth,predicted) * recall_manual(truth, predicted) / (precision_manual(truth, predicted) + recall_manual(truth, predicted))\n",
    "    \n",
    "    return f1_score # CHANGE IT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the results of your four function on two arrays (`truth`, `predicted`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth     = np.array([0,1,0,1,1,1,1,0,0,1,1,0,0,1,1,0,1])\n",
    "predicted = np.array([1,0,0,0,1,0,0,1,1,0,1,1,1,0,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score_manual = accuracy_manual(truth, predicted) # CHANGE IT\n",
    "precision_score_manual = precision_manual(truth, predicted) # CHANGE IT\n",
    "recall_score_manual = recall_manual(truth, predicted) # CHANGE IT\n",
    "f1_score_manual = f1_manual(truth, predicted) # CHANGE IT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show your results here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.29411764705882354, 0.4, 0.4, 0.4000000000000001)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(accuracy_score_manual, precision_score_manual, recall_score_manual, f1_score_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 13: Save models into a file using pickle (0.4 pt)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you need to pick the best model using cross-validation and deploy it as a pickle file. For this task, we will use the diabetes data that we used for Homework 1. This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage. You can find it in the homework folder.\n",
    "\n",
    "- Load the dataset into `diabetes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv(\"datasets/diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the dataset into two parts: attributes (`X`) and labels (Outcome, `y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes.drop('Outcome', axis=1) # CHANGE IT\n",
    "y = diabetes.iloc[:, -1] # CHANGE IT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is as follows:\n",
    "\n",
    "1. Use scikit-learn's `train_test_split` function to divide the dataset into four parts.\n",
    "- Follow the instruction below carefully to get a point!.\n",
    "    - Use `X` and `y`.\n",
    "    - Assign 10% to a test set.\n",
    "    - Use our random state (`RANDOM_STATE`)\n",
    "    - Enable stratify option.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the assigned values and write the train_test_split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size= 0.1,  random_state= RANDOM_STATE, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create an instance of an SVC classifier without setting any constraint.\n",
    "3. Run grid search with a list of two dictionaries. \n",
    "    - In the first dictionary, you should examine 'poly' kernel, with degree `[3, 4 5]`. \n",
    "    - In the second dictionary, you should test two kernels `['linear', 'rbf']` with a list of C values `[5, 10, 100]`. \n",
    "    - Use **AUPRC** as its scoring measure. Set `cv=3` for grid search cross-validation. \n",
    "    - Use the training set to train the grid search instance.\n",
    "4. Save the best classifier into the variable called `svm_best_classifier_dash` and save the trained model into `model_diabetes.pickle` using pickle. When saving your model, do not specify any folder.\n",
    " - **Do not use your own specific name for the model!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "para_grid_poly =  {'kernel': ['poly'], 'degree': [3, 4, 5]}\n",
    "para_grid_oth = {'kernel': ['linear', 'rbf'], 'C': [5, 10, 100]}\n",
    "para_grids = [para_grid_poly, para_grid_oth]\n",
    "\n",
    "grid_search = GridSearchCV(svc, para_grids, scoring='average_precision', cv=3)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "svm_best_classifier_dash = grid_search.best_estimator_\n",
    "\n",
    "with open('model_diabetes.pickle', 'wb') as model_file:\n",
    "    pickle.dump(svm_best_classifier_dash, model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Show your classifier here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_best_classifier_dash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Using the best classifier, report the **test** score to `svm_test_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "        0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "        0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
       "       dtype=int64),\n",
       " 0.7467532467532467)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = svm_best_classifier_dash.predict(X_test)\n",
    "\n",
    "svm_test_score = svm_best_classifier_dash.score(X_test, y_test)# CHANGE IT\n",
    "\n",
    "y_pred_test , svm_test_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 14: DASH deployment (0.2 pt)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will run DASH application by using the model `model_diabetes.pickle` you exported with the project files in the `webplatform_dash` folder. Locate the model in the same folder with this jupeter notebook, and go into `webplatform_dash` folder. There you can run your own DASH application as you learned from Lab 5. Note that you should **not** move the model file into `webplatform_dash`.\n",
    "\n",
    "- Submit a screenshot with your model file into one zip file in a separate submission form for your DASH project. For the details of the DASH deployment, check out Lab 5."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "2511362d7eaf04f9267976467a4d4f95db9fe8d018187d0f490bf8e1d8c4b042"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
